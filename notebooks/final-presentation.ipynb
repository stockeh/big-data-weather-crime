{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1><center>Weather or Not, There is Crime</center></h1>\n",
    "<center>\n",
    "*Jason Stock, Tom Cavey, Amber Lee*  \n",
    "*Relationships between crime and weather patterns in Chicago*\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuralnetworks as nn\n",
    "import mlutils as ml\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import pickle\n",
    "\n",
    "class Models:\n",
    "    \n",
    "    trained_nn = []\n",
    "    networks   = []\n",
    "    \n",
    "    def __init__(self, num_districts, networks):\n",
    "        \"\"\"Initialize number of districts and repsective networks\"\"\"\n",
    "        self.num_districts = num_districts\n",
    "        self.networks = networks\n",
    "        \n",
    "    def sampler(self, data, features, targets):\n",
    "        \"\"\"Sample the data to set features, X, and targets, T.\"\"\"\n",
    "        X = data.iloc[:, np.r_[features]]\n",
    "        T = data.iloc[:, np.r_[targets]]\n",
    "        return np.array(X), np.array(T)\n",
    "\n",
    "    def train(self, iterations=100, normalize=True, partition=True):\n",
    "        \"\"\"Train each network and save the trained nnet object to trained_nn\"\"\"\n",
    "        for district in range(self.num_districts):\n",
    "            data = pd.read_csv('../Output/WeeklyOutput/wc'+str(district + 1)+'.csv', sep=',', low_memory=False, \n",
    "            names = ['date', 'dry', 'wet', 'wind', 'humidity', 'district', 'homicide', 'robbery',\n",
    "                     'battery', 'assault', 'burglary', 'theft', 'motor', 'weapons']).iloc[70:]\n",
    "            if normalize:\n",
    "                cols_to_norm = ['dry', 'wet', 'wind', 'humidity']\n",
    "                data[cols_to_norm] = data[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "            X, T = sampler(data, range(1,5), range(6,14))\n",
    "        \n",
    "            if partition: \n",
    "                train_f = 0.80\n",
    "                Xtrain, Ttrain, _, _ = ml.partition(X, T, (train_f, 1 - train_f))\n",
    "\n",
    "                nnet = nn.NeuralNetwork(Xtrain.shape[1], self.networks[district], Ttrain.shape[1])\n",
    "                nnet.train(Xtrain, Ttrain, iterations)\n",
    "            else:  \n",
    "                nnet = nn.NeuralNetwork(X.shape[1], self.networks[district], T.shape[1]) \n",
    "                nnet.train(X, T, iterations)\n",
    "            \n",
    "            self.trained_nn.append(nnet)\n",
    "    \n",
    "    def use(self, data, return_all=True, district=None):\n",
    "        \"\"\"Prints a table of all or specific district results based off provided data.\n",
    "        The data shall be the weather for the day in the form:\n",
    "        [dry-bulb-temp, wet-bulb-temp, wind-speed, relative-humidity]\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        if return_all:\n",
    "            for i, network in enumerate(self.trained_nn):\n",
    "                Y = np.round(network.use(data)[0])\n",
    "                result = np.insert(Y, 0, i+1)\n",
    "                results.append(result)\n",
    "        elif district is not None:\n",
    "            Y = np.round(self.trained_nn[district - 1].use(data)[0])\n",
    "            results.append(np.insert(Y, 0, district))\n",
    "        else:\n",
    "            print('ERROR, return_all = True, or set to false and specify district number.')\n",
    "        \n",
    "        df = pd.DataFrame(results, columns=['district', 'homicide', 'robbery', 'battery', 'assault',\n",
    "                                            'burglary', 'theft', 'motor', 'weapons']).astype(int)\n",
    "        print(df.to_string(index=False))\n",
    "    \n",
    "def save_pickle():\n",
    "    \"\"\"Train Models class with defined networks.\n",
    "    Then save class to a .pickle file\"\"\"\n",
    "    networks = [\n",
    "                [65, 76, 21, 49], # district 1\n",
    "                [65, 76, 21, 49], # district 2\n",
    "                [65, 76, 21, 49], # district 3\n",
    "                [65, 76, 21, 49], # district 4\n",
    "                [5], # district 5\n",
    "                [65, 76, 21, 49], # district 6\n",
    "                [65, 76, 21, 49], # district 7\n",
    "                [65, 76, 21, 49], # district 8\n",
    "                [65, 76, 21, 49], # district 9\n",
    "               ]\n",
    "\n",
    "    M = Models(9, networks)\n",
    "    M.train()\n",
    "    \n",
    "    outfile = open('trained_models.pickle', 'wb')\n",
    "    pickle.dump(M, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "    outfile.close()\n",
    "    \n",
    "def sampler(data, a, b):\n",
    "    \"\"\"Sample the data to set features, X, and targets, T.\"\"\"\n",
    "    X = data.iloc[:, np.r_[a]]\n",
    "    T = data.iloc[:, np.r_[b]]\n",
    "        \n",
    "    return np.array(X), np.array(T)\n",
    "\n",
    "def get_values(X, T, network, train_f, itr, partition = False):\n",
    "    \"\"\"Get test results and error trace\"\"\"\n",
    "    if partition: \n",
    "        Xtrain, Ttrain, Xtest, T = ml.partition(X, T, (train_f, 1 - train_f))\n",
    "        \n",
    "        nnet = nn.NeuralNetwork(Xtrain.shape[1], network, Ttrain.shape[1])\n",
    "        nnet.train(Xtrain, Ttrain, itr)\n",
    "        Y = nnet.use(Xtest)\n",
    "    else:  \n",
    "        nnet = nn.NeuralNetwork(X.shape[1], network, T.shape[1]) \n",
    "        nnet.train(X, T, itr)\n",
    "        Y = nnet.use(X)\n",
    "        \n",
    "    return Y, T, nnet.getErrorTrace()\n",
    "\n",
    "def network_test(district='4'):\n",
    "    \"\"\"Display a run with 20 networks - graphing the error output.  Data is not partitioned\"\"\"\n",
    "    data = pd.read_csv('../Output/WeeklyOutput/wc'+district+'.csv', sep=',', low_memory=False, \n",
    "            names = ['date', 'dry', 'wet', 'wind', 'humidity', 'district', 'homicide', 'robbery',\n",
    "                     'battery', 'assault', 'burglary', 'theft', 'motor', 'weapons']).iloc[70:]\n",
    "    \n",
    "    cols_to_norm = ['dry', 'wet', 'wind', 'humidity']\n",
    "    data[cols_to_norm] = data[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "    X, T = sampler(data, range(1, 5), range(6,14))\n",
    "\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    numberItr = 1200\n",
    "    train_f = 0.8\n",
    "    er = []\n",
    "    networks = []\n",
    "    for i in range(20):\n",
    "        a = random.sample(range(1, 100), np.random.randint(1, 6))\n",
    "        Y, _T, error = get_values(X, T, a, train_f, numberItr)\n",
    "        er.append(error)\n",
    "        networks.append(a)\n",
    "        numberItr = int(1.05 * numberItr)\n",
    "\n",
    "    color=iter(cm.rainbow(np.linspace(0,1,20)))\n",
    "    plt.figure(figsize=(18,8))\n",
    "    for i, pl in enumerate(er):\n",
    "        plt.plot(pl, c=next(color), label = 'Network '+str(networks[i]))\n",
    "\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def bar_test(year=5, district='4'):\n",
    "    \"\"\"Display the crime data for a given year and district\"\"\"\n",
    "    def bar_crime(data, year):\n",
    "        col = ['homicide', 'robbery','battery', 'assault', 'burglary', 'theft', 'motor', 'weapons']\n",
    "        plt.figure(figsize=(18,25))\n",
    "\n",
    "        for i in range(len(col)):\n",
    "            plt.subplot(4,2,i+1)  \n",
    "            y = data[col[i]][52*(year - 1):52*year]\n",
    "            x = np.arange(len(y))\n",
    "            z = np.polyfit(x, y, 3)\n",
    "\n",
    "            p = np.poly1d(z)\n",
    "            p30 = np.poly1d(np.polyfit(x, y, 15))\n",
    "            xp = np.linspace(0, len(y) - 1, 50)\n",
    "\n",
    "            plt.bar(x, y, color='tan')\n",
    "            _ = plt.plot(xp, p(xp), 'k--', xp, p30(xp), 'b-', lw=2.5)\n",
    "            plt.title(col[i])\n",
    "            plt.xlabel('days (samples)'), plt.ylabel('num crimes') \n",
    "\n",
    "        plt.show() \n",
    "\n",
    "    data = pd.read_csv('../Output/WeeklyOutput/wc'+district+'.csv', sep=',', low_memory=False, \n",
    "                   names = ['date', 'dry', 'wet', 'wind', 'humidity', 'district', 'homicide', 'robbery',\n",
    "                            'battery', 'assault', 'burglary', 'theft', 'motor', 'weapons'])\n",
    "    bar_crime(data, year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT ABOVE FILE\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "## - BLAH\n",
    "## - BLAH\n",
    "## - BLAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_test(year=5, district='5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network_test(district='4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## - BLAH\n",
    "## - BLAH\n",
    "## - BLAH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application\n",
    "\n",
    "## - BLAH\n",
    "## - BLAH\n",
    "## - BLAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#from final import Models\n",
    "\n",
    "fp = open('trained_models.pickle', 'rb')\n",
    "trained_models = pickle.load(fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "district  homicide  robbery  battery  assault  burglary  theft  motor  weapons\n",
      "       1         0        4       15        5         8     53     -5       -1\n",
      "       2         0       13       30        7        28    132     18       -1\n",
      "       3         0        2       29        8         1     21     10        1\n",
      "       4         0       11       42       15         5    217     15        1\n",
      "       5         4       54      209       76        46    264     54       21\n",
      "       6         3       47      223       74        77    182     47       18\n",
      "       7         1       37      133       47        50    128     31        9\n",
      "       8         0       11       71       28        13     71     16        5\n",
      "       9         1       15      101       38        22     81     22        8\n"
     ]
    }
   ],
   "source": [
    "dry_bulb_temp = 30\n",
    "wet_bulb_temp = 28\n",
    "wind_speed = 5\n",
    "relative_humidity = 60\n",
    "\n",
    "data = [dry_bulb_temp, wet_bulb_temp, wind_speed, relative_humidity]\n",
    "trained_models.use(data, return_all=True, district=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges\n",
    "\n",
    "## - BLAH\n",
    "## - BLAH\n",
    "## - BLAH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "## - BLAH\n",
    "## - BLAH\n",
    "## - BLAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
